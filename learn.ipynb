{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sand_good = pd.read_csv('data/mined-data/sand-change-(good)/sand-only/all.dat', sep=\",\")\n",
    "buried_good = pd.read_csv('data/mined-data/sand-change-(good)/buried/all.dat', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodX = sand_good.append(buried_good).to_numpy()\n",
    "goodY = np.array([0] * len(sand_good) + [1] * len(buried_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "buried_1 = pd.read_csv('data/mined-data/new/16-10-2020-1/all.dat', sep=\",\") # label up, #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model on 'up' data\n",
    "model = LogisticRegression(solver='liblinear', penalty='l1', C=100, random_state=42).fit(goodX, goodY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996124281377172"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(goodX, goodY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.961038961038961"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model on unseen data (up)\n",
    "model.score(buried_1, [1] * len(buried_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "buried_2 = pd.read_csv('data/mined-data/new/16-10-2020-2/all.dat', sep=\",\") # buried_2 = up #1 (bad)\n",
    "buried_3 = pd.read_csv('data/mined-data/new/16-10-2020-3/all.dat', sep=\",\") # buried_3 = down #1\n",
    "buried_4 = pd.read_csv('data/mined-data/new/16-10-2020-4/all.dat', sep=\",\") # buried_4 = down #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(buried_2, [1] * len(buried_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "buried_5 = pd.read_csv('data/mined-data/new/21-10-2020-3/all.dat', sep=\",\") # buried_5 = up #1\n",
    "buried_6 = pd.read_csv('data/mined-data/new/21-10-2020-4/all.dat', sep=\",\") # buried_6 = up #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2880184331797235\n",
      "0.007992007992007992\n"
     ]
    }
   ],
   "source": [
    "# test for 'down' data\n",
    "print(model.score(buried_3, [1] * len(buried_3)))\n",
    "print(model.score(buried_4, [1] * len(buried_4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7025948103792415\n",
      "0.8363273453093812\n"
     ]
    }
   ],
   "source": [
    "# make sure it somewhat works on 'up' data\n",
    "print(model.score(buried_5, [1] * len(buried_5)))\n",
    "print(model.score(buried_6, [1] * len(buried_6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sand only to check if it works\n",
    "sand_1 = pd.read_csv('data/mined-data/new/08-10-2020-1/all.dat', sep=\",\")\n",
    "sand_2 = pd.read_csv('data/mined-data/new/12-10-2020-1/all.dat', sep=\",\")\n",
    "sand_3 = pd.read_csv('data/mined-data/new/12-10-2020-2/all.dat', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8095502498611882\n",
      "0.3596551724137931\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "print(model.score(sand_1, [0] * len(sand_1)))\n",
    "print(model.score(sand_2, [0] * len(sand_2)))\n",
    "print(model.score(sand_3, [0] * len(sand_3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't work very well. Changing parameters doesn't help. Only way is to combine all the good data and train with cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load all data and label them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sand only\n",
    "sand_good = pd.read_csv('data/mined-data/sand-change-(good)/sand-only/all.dat', sep=\",\")\n",
    "sand_08 = pd.read_csv('data/mined-data/new/08-10-2020-1/all.dat', sep=\",\")\n",
    "sand_121 = pd.read_csv('data/mined-data/new/12-10-2020-1/all.dat', sep=\",\")\n",
    "sand_122 = pd.read_csv('data/mined-data/new/12-10-2020-2/all.dat', sep=\",\")\n",
    "\n",
    "# buried\n",
    "buried_good = pd.read_csv('data/mined-data/sand-change-(good)/buried/all.dat', sep=\",\")\n",
    "\n",
    "buried_082_near_1 = pd.read_csv('data/mined-data/new/08-10-2020-2/all.dat', sep=\",\")\n",
    "buried_083_10cm_2 = pd.read_csv('data/mined-data/new/08-10-2020-3/all.dat', sep=\",\")\n",
    "buried_084_10cm_3 = pd.read_csv('data/mined-data/new/08-10-2020-4/all.dat', sep=\",\")\n",
    "buried_085_18cm_4 = pd.read_csv('data/mined-data/new/08-10-2020-5/all.dat', sep=\",\")\n",
    "buried_086_8cm_4 = pd.read_csv('data/mined-data/new/08-10-2020-6/all.dat', sep=\",\")\n",
    "\n",
    "buried_123_7cm_1 = pd.read_csv('data/mined-data/new/12-10-2020-3/all.dat', sep=\",\")\n",
    "buried_124_7cm_1 = pd.read_csv('data/mined-data/new/12-10-2020-4/all.dat', sep=\",\")\n",
    "buried_125_7cm_3 = pd.read_csv('data/mined-data/new/12-10-2020-5/all.dat', sep=\",\")\n",
    "\n",
    "buried_161_up_1 = pd.read_csv('data/mined-data/new/16-10-2020-1/all.dat', sep=\",\")\n",
    "buried_162_up_1 = pd.read_csv('data/mined-data/new/16-10-2020-2/all.dat', sep=\",\")\n",
    "buried_163_down_1 = pd.read_csv('data/mined-data/new/16-10-2020-3/all.dat', sep=\",\")\n",
    "buried_164_down_1 = pd.read_csv('data/mined-data/new/16-10-2020-4/all.dat', sep=\",\")\n",
    "\n",
    "buried_211_down_1 = pd.read_csv('data/mined-data/new/21-10-2020-1/all.dat', sep=\",\")\n",
    "buried_212_down_1 = pd.read_csv('data/mined-data/new/21-10-2020-2/all.dat', sep=\",\")\n",
    "buried_213_up_1 = pd.read_csv('data/mined-data/new/21-10-2020-3/all.dat', sep=\",\")\n",
    "buried_214_up_1 = pd.read_csv('data/mined-data/new/21-10-2020-4/all.dat', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sand_all = [sand_good, sand_08, sand_121, sand_122]\n",
    "buried_all = [buried_good,\n",
    "             buried_082_near_1, buried_083_10cm_2, buried_084_10cm_3, buried_085_18cm_4, buried_086_8cm_4,\n",
    "             buried_123_7cm_1, buried_124_7cm_1, buried_125_7cm_3, \n",
    "             buried_161_up_1, buried_162_up_1, buried_163_down_1, buried_164_down_1, \n",
    "             buried_211_down_1, buried_212_down_1, buried_213_up_1, buried_214_up_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "slen = []\n",
    "for s in sand_all:\n",
    "    slen.append(len(s))\n",
    "blen = []\n",
    "for b in buried_all:\n",
    "    blen.append(len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sand: [7481, 1801, 2900, 2300] -> 14482\n",
      "buried: [8000, 1301, 1601, 1801, 1901, 801, 1602, 1701, 1595, 1001, 1401, 1302, 1001, 3001, 3401, 501, 501] -> 32412\n"
     ]
    }
   ],
   "source": [
    "print('sand:', slen, '->' , np.sum(slen))\n",
    "print('buried:', blen, '->' , np.sum(blen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, buried data is much more than sand data. We can remove some of it and use it as the test data afterwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "buried_all = [buried_good, buried_211_down_1, buried_212_down_1, buried_213_up_1, buried_214_up_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sand: 14482\n",
      "buried: 15404\n"
     ]
    }
   ],
   "source": [
    "sand = np.concatenate(tuple(sand_all))\n",
    "buried = np.concatenate(tuple(buried_all))\n",
    "print('sand:', len(sand))\n",
    "print('buried:', len(buried))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((sand, buried))\n",
    "Y = [0] * len(sand) + [1] * len(buried)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', penalty='l1', C=100, random_state=42).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9910995114769457"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19830899308224442\n",
      "0.018738288569643973\n",
      "0.27484730705163796\n",
      "0.19147816938453446\n",
      "0.02746566791510612\n",
      "0.16853932584269662\n",
      "0.4497354497354497\n",
      "0.21379310344827587\n",
      "0.967032967032967\n",
      "0.9421841541755889\n",
      "0.8855606758832565\n",
      "0.971028971028971\n"
     ]
    }
   ],
   "source": [
    "# test model on unseen data:\n",
    "print(model.score(buried_082_near_1, [1] * len(buried_082_near_1))) #\n",
    "print(model.score(buried_083_10cm_2, [1] * len(buried_083_10cm_2))) #\n",
    "print(model.score(buried_084_10cm_3, [1] * len(buried_084_10cm_3))) #\n",
    "print(model.score(buried_085_18cm_4, [1] * len(buried_085_18cm_4))) #\n",
    "print(model.score(buried_086_8cm_4, [1] * len(buried_086_8cm_4))) #\n",
    "print(model.score(buried_123_7cm_1, [1] * len(buried_123_7cm_1))) #\n",
    "print(model.score(buried_124_7cm_1, [1] * len(buried_124_7cm_1))) #\n",
    "print(model.score(buried_125_7cm_3, [1] * len(buried_125_7cm_3))) #\n",
    "print(model.score(buried_161_up_1, [1] * len(buried_161_up_1)))\n",
    "print(model.score(buried_162_up_1, [1] * len(buried_162_up_1)))\n",
    "print(model.score(buried_163_down_1, [1] * len(buried_163_down_1)))\n",
    "print(model.score(buried_164_down_1, [1] * len(buried_164_down_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It somewhat seems like model can correctly predict for newer unseen data, but fails for old data. This might be because sand's properties changed over time, because of the humidity and whatnot. Let's search optimal parameters for this model and do some more tests on newer data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
